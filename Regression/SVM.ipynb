{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0693c388",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "Support Vector Machine is a versatile algorithm that can be applied to linear or non-linear datasets. The idea behind support vector machines is to create a decision boundary between classes such that the margins between both classes are maximized. \n",
    "\n",
    "If instances are to be strictly imposed off the margins, this is called hard margin classification. However this method is sensitive to outliers and only works if the data is linearly separable. \n",
    "\n",
    "Alternatively, soft margin classification can be employed for more flexibility. The idea is to optimize the trade-off between margin violations and keeping the margins large. Allowing some observations to fall on the wrong side of the margin makes the margin 'soft'.\n",
    " \n",
    "# Kernels\n",
    "\n",
    "The SVM allows us to utilize different transformative kernels which can be used depending on the nature of our dataset. These include linear, polynomial and RBF kernel (among others). The model works best on small to medium scale datasets with high complexity.\n",
    "\n",
    "**Polynomial Kernel**\n",
    "\n",
    "For non-linear datasets, sometimes applying quadratic or polynomial transformation can result in a linearly separable dataset. This then allows us to apply linear SVM. However, low polynomial degrees wonâ€™t be effective with very complex datasets while high polynomials tend to create numerous features, which can cause a combinatorial explosion thereby reducing model efficiency. \n",
    "\n",
    "SVM's apply kernel tricks that allow us to achieve the results produced by polynomial transformations without actually increasing the number of features. \n",
    "\n",
    "**Gaussian Radial Basis Function Kernel**\n",
    "\n",
    "This kernel is particularly useful for overlapping features. The Radial kernel utilizes a similarity metric to establish closely related observations. The smaller the distance the greater the using influence these observations have on each other. The gamma hyperparameter is tweaked to perform regularization.\n",
    "\n",
    "\n",
    "\n",
    "# SVM Hyperparameters\n",
    "\n",
    "The C hyperparameter can be tweaked to control the balance between margins and margin violations. Lower values of C leads to wider margins but more margin violations. To the contrary, using a high C value produces a narrow margin and fewer margin violation. Lower values of C increase bias (regularization) while Higher values of C increase variance.\n",
    "\n",
    "\n",
    "# SVM Pros and Cons\n",
    "\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- Highly flexible, particularly due to kernel tricks.\n",
    "\n",
    "**Cons**\n",
    "\n",
    " - Support vector machines expect features to be scaled.\n",
    " \n",
    " - Inefficient to scale on large datasets.\n",
    " \n",
    " - Do not provide probability estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9627b",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059881ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b68e81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LungCap</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Caesarean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.475</td>\n",
       "      <td>6</td>\n",
       "      <td>62.1</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.125</td>\n",
       "      <td>18</td>\n",
       "      <td>74.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.550</td>\n",
       "      <td>16</td>\n",
       "      <td>69.7</td>\n",
       "      <td>no</td>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.125</td>\n",
       "      <td>14</td>\n",
       "      <td>71.0</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.800</td>\n",
       "      <td>5</td>\n",
       "      <td>56.9</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LungCap  Age  Height Smoke  Gender Caesarean\n",
       "0    6.475    6    62.1    no    male        no\n",
       "1   10.125   18    74.7   yes  female        no\n",
       "2    9.550   16    69.7    no  female       yes\n",
       "3   11.125   14    71.0    no    male        no\n",
       "4    4.800    5    56.9    no    male        no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('LungCapData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06657803",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64dc8c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((725, 8), (725,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictors and Target\n",
    "X = df.drop(columns = ['LungCap'])\n",
    "y = df['LungCap']\n",
    "\n",
    "# Instantiate one-hot encoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# columns to be one hot encoded\n",
    "ct = make_column_transformer(\n",
    "\n",
    "    (ohe, ['Smoke', 'Gender', 'Caesarean']),\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "# predictors and target variable\n",
    "X = np.array(ct.fit_transform(X))\n",
    "y = np.array(y)\n",
    "\n",
    "# Checck input and target variable shape\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67bbc651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized feature Mean: 0.0\n",
      "Standardized feature SD : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing subsets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 911)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print('Standardized feature Mean:',  X_train.mean().round())\n",
    "print('Standardized feature SD :',   X_train.std().round())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089bead",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795ffcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the SVM Classifier\n",
    "svr = SVR(kernel = 'linear')\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4d321",
   "metadata": {},
   "source": [
    "# 4. Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5823c54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 1.0039382581330274\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "# Mean squared error\n",
    "print('Mean Squared Error :', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e1263",
   "metadata": {},
   "source": [
    "# 5. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa870d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82962924 0.83983211 0.88385988 0.7823923  0.85396122 0.88573589\n",
      " 0.84117599 0.8524749  0.87046444 0.79728231]\n",
      "R2: 84.368 %\n",
      "R2 Standard Deviation: 3.227 %\n"
     ]
    }
   ],
   "source": [
    "# 10 fold cross validation\n",
    "R2 = cross_val_score(estimator = svr,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             cv = 10)\n",
    "\n",
    "# Cross validation accuracy and standard deviation\n",
    "print(R2)\n",
    "print(\"R2: {:.3f} %\".format(R2.mean()*100))\n",
    "print(\"R2 Standard Deviation: {:.3f} %\".format(R2.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054560c",
   "metadata": {},
   "source": [
    "# 6. Hyperparametric Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926235c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 84.17 %\n",
      "Best Parameters: {'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
    "              ]\n",
    "\n",
    "\n",
    "# Configure GridSearchCV\n",
    "grid_search = GridSearchCV(estimator = svr,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'r2',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "# Initiate Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Print Results\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e60fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 84.17 %\n",
      "Best Parameters: {'kernel': 'linear', 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search CV\n",
    "parameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n",
    "              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},]\n",
    "\n",
    "\n",
    "# Configure GridSearchCV\n",
    "random_search = RandomizedSearchCV(estimator = svr,\n",
    "                           param_distributions = parameters,\n",
    "                           scoring = 'r2',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "\n",
    "# Initiate Search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract Tuned Parameters and Predictive Accuracy\n",
    "tuned_params = random_search.best_params_\n",
    "tuned_score = random_search.best_score_\n",
    "best_estimator = random_search.best_estimator_\n",
    "\n",
    "# Print Results\n",
    "print(\"Best Accuracy: {:.2f} %\".format(random_search.best_score_*100))\n",
    "print(\"Best Parameters:\", tuned_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

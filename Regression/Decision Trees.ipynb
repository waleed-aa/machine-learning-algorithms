{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0693c388",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "Decision Trees is a non-linear model that can be used for regression and classification. The structure of a decision tree consists of root nodes, leaf nodes and branches. \n",
    "\n",
    "\n",
    "# Training Process\n",
    "\n",
    "Decision Trees make predictions by stratifying or segmenting at each split using a criteria. It uses a top-down greedy approach called recursive binary splitting. \n",
    "\n",
    "The first split (root node) is the most influential at predicting the target variable. The model considers all predictors and all possible values for the splitting point for each predictor. For classification problems the tree makes splits by finding the cut points that minimize the misclassification rate. For regression problems, the tree splits based on minimizing the residual standard error.\n",
    "\n",
    "The model continues to make splits until a criterion is met. For example, the tree continues until no segments contain more than 10 observations. For regression, the mean predicted response in the terminal node is the final output. For classification, we detect the most frequently occurring class in the selected region.  For classification tress the Gini Index and Entropy are better to evaluate node purity. Values closer to zero imply that all training instances belong to the same class. When a region is completely pure, it cannot split further.\n",
    "\n",
    "If left unconstrained, the model tends to learn the training data quite well (overfitting). However various hyperparameters can be tweaked to restrict the model's freedom and control overfitting.\n",
    "\n",
    "\n",
    "# Decision Tree Hyperparameters\n",
    "\n",
    "Increasing min and reducing max will apply regularization. \n",
    "\n",
    "- min_samples_split: The minumum number of samples in a node\n",
    "\n",
    "- min_samples_leaf:  The minumum number of samples in a leaf\n",
    "\n",
    "- max_leaf_nodes: maximum number of leaf nodes\n",
    "\n",
    "- max_features: maximum number of features for splitting at each   node.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Decision Trees Pros and Cons\n",
    "\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- Easy to interpret\n",
    "\n",
    "- Allows us to determine feature importance. This could be used as a method conduct feature extraction.\n",
    "\n",
    "\n",
    "**Cons**\n",
    "\n",
    "- Sensitive to variation in training data\n",
    "\n",
    "- Is prone to overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9627b",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0282e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574bada7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LungCap</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Caesarean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.475</td>\n",
       "      <td>6</td>\n",
       "      <td>62.1</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.125</td>\n",
       "      <td>18</td>\n",
       "      <td>74.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.550</td>\n",
       "      <td>16</td>\n",
       "      <td>69.7</td>\n",
       "      <td>no</td>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.125</td>\n",
       "      <td>14</td>\n",
       "      <td>71.0</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.800</td>\n",
       "      <td>5</td>\n",
       "      <td>56.9</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LungCap  Age  Height Smoke  Gender Caesarean\n",
       "0    6.475    6    62.1    no    male        no\n",
       "1   10.125   18    74.7   yes  female        no\n",
       "2    9.550   16    69.7    no  female       yes\n",
       "3   11.125   14    71.0    no    male        no\n",
       "4    4.800    5    56.9    no    male        no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('LungCapData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06657803",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636f9944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((725, 8), (725,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictors and Target\n",
    "X = df.drop(columns = ['LungCap'])\n",
    "y = df['LungCap']\n",
    "\n",
    "# Instantiate one-hot encoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# columns to be one hot encoded\n",
    "ct = make_column_transformer(\n",
    "\n",
    "    (ohe, ['Smoke', 'Gender', 'Caesarean']),\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "# predictors and target variable\n",
    "X = np.array(ct.fit_transform(X))\n",
    "y = np.array(y)\n",
    "\n",
    "# Checck input and target variable shape\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64dc8c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized feature Mean: 0.0\n",
      "Standardized feature SD : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing subsets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 911)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print('Standardized feature Mean:',  X_train.mean().round())\n",
    "print('Standardized feature SD :',   X_train.std().round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb93ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((580, 8), (580,), (145, 8), (145,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebccd41",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "795ffcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Decision Tree Classifier on default parameters\n",
    "dt = DecisionTreeRegressor(random_state = 0)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4d321",
   "metadata": {},
   "source": [
    "# 4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5823c54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 1.98515625\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Mean squared error\n",
    "print('Mean Squared Error :', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e1263",
   "metadata": {},
   "source": [
    "# 5. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa870d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48061774 0.71070523 0.66352599 0.5700009  0.68686148 0.77086239\n",
      " 0.67520901 0.73646311 0.63624062 0.52950831]\n",
      "R2: 64.600 %\n",
      "R2 Standard Deviation: 8.808 %\n"
     ]
    }
   ],
   "source": [
    "# 10 fold cross validation\n",
    "R2 = cross_val_score(estimator = DecisionTreeRegressor(),\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             cv = 10)\n",
    "\n",
    "# Cross validation accuracy and standard deviation\n",
    "print(R2)\n",
    "print(\"R2: {:.3f} %\".format(R2.mean()*100))\n",
    "print(\"R2 Standard Deviation: {:.3f} %\".format(R2.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054560c",
   "metadata": {},
   "source": [
    "# 6. Hyperparametric Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e60fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 77.88 %\n",
      "Best Parameters: {'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV\n",
    "\n",
    "# Hyperparameters\n",
    "param_grid = [{\n",
    "     'max_depth': [6, 10],\n",
    "     'max_features': ['auto'],\n",
    "     'min_samples_leaf': [3, 5],\n",
    "     'min_samples_split': [4, 6]}]\n",
    "\n",
    "\n",
    "# Configure GridSearchCV\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(),\n",
    "                           param_grid, cv=5, scoring = 'r2',\n",
    "                            n_jobs=-1)\n",
    "# Initiate Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract Tuned Parameters and Predictive Accuracy\n",
    "tuned_params = grid_search.best_params_\n",
    "tuned_score = grid_search.best_score_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Print Results\n",
    "print(\"Best R2: {:.2f} %\".format(grid_search.best_score_*100))\n",
    "print(\"Best Parameters:\", tuned_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295a3e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 77.87 %\n",
      "Best Parameters: {'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search\n",
    "\n",
    "# Hyperparameters\n",
    "param_grid = {\n",
    "        \"max_depth\": [6, 8, 10, 12, 14],\n",
    "        \"max_features\": ['auto'],\n",
    "        \"min_samples_leaf\": [2, 3, 4],\n",
    "        \"min_samples_split\": [2, 3, 4, 5]}\n",
    "\n",
    "# Randomized Search initialization\n",
    "random_search = RandomizedSearchCV(DecisionTreeRegressor(), param_grid, n_iter=32,\n",
    "                                        scoring=\"r2\", cv=5,\n",
    "                                        n_jobs=-1, random_state=911)\n",
    "# Initiate Search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract Tuned Parameters and Predictive Accuracy\n",
    "tuned_params = random_search.best_params_\n",
    "tuned_score = random_search.best_score_\n",
    "best_estimator = random_search.best_estimator_\n",
    "\n",
    "# Print Results\n",
    "print(\"Best Accuracy: {:.2f} %\".format(random_search.best_score_*100))\n",
    "print(\"Best Parameters:\", tuned_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

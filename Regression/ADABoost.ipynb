{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0693c388",
   "metadata": {},
   "source": [
    "# AdaBoost \n",
    "\n",
    "Adaptive Boosting is an iterative sequence of weak algorithms, typically decision trees. The classifier starts with a base decision tree model and each subsequent model iteratively learns from the mistakes of its predecessor and updates the weights and biases of the instances that were misclassified.\n",
    "\n",
    "\n",
    "# Training Process\n",
    "\n",
    "The algorithm starts with an initial base model and makes predictions with equal weights for all features. The instances misclassified by this base model are boosted and the subsequent model then performs better than its predecessor. This sequence continues until all predictors are trained. The model then makes predictions by using the class that receives the majority of the weighted votes across all models.\n",
    "\n",
    "There are notable differences between Random Forests and Adaboost. When making predictions, random forests apply an equal vote to all trees in the ensemble while Adaboost applies greater weights to trees that minimize the error rate. Moreover, Adaboost operates by training the model sequentially where each tree is fit on a modified version of the original dataset. while Random Forests apply bagging based resampling technique in a parallel fashion. \n",
    "\n",
    "# AdaBoost Hyperparameters\n",
    "\n",
    "\n",
    "- n_estimators : The number of trees.\n",
    "\n",
    "- learning_rate: Weight applied to each model at each boosting iteration\n",
    "\n",
    "- algorithm: If model supports probabilistic output use 'SAMME.R' if model produces discreet output 1/0 use  'SAMME'.\n",
    "\n",
    "\n",
    "\n",
    "# AdaBoost Pros and Cons\n",
    "\n",
    "\n",
    "**Pros**\n",
    "\n",
    "- Very few hyperparameters for tune.\n",
    "\n",
    "- They are non- parametric models and donâ€™t require data-pre-processing (feature scaling or one-hot-encoding)\n",
    "\n",
    "- Good for non-linear datasets\n",
    "\n",
    "\n",
    "**Cons**\n",
    "\n",
    "\n",
    "- Cannot be parallelized as each model is trained based on the results of the previous model.\n",
    "\n",
    "- Much slower than other boosting models such as XGboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9627b",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059881ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b68e81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LungCap</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Caesarean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.475</td>\n",
       "      <td>6</td>\n",
       "      <td>62.1</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.125</td>\n",
       "      <td>18</td>\n",
       "      <td>74.7</td>\n",
       "      <td>yes</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.550</td>\n",
       "      <td>16</td>\n",
       "      <td>69.7</td>\n",
       "      <td>no</td>\n",
       "      <td>female</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.125</td>\n",
       "      <td>14</td>\n",
       "      <td>71.0</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.800</td>\n",
       "      <td>5</td>\n",
       "      <td>56.9</td>\n",
       "      <td>no</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LungCap  Age  Height Smoke  Gender Caesarean\n",
       "0    6.475    6    62.1    no    male        no\n",
       "1   10.125   18    74.7   yes  female        no\n",
       "2    9.550   16    69.7    no  female       yes\n",
       "3   11.125   14    71.0    no    male        no\n",
       "4    4.800    5    56.9    no    male        no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('LungCapData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06657803",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c22e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((725, 8), (725,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictors and Target\n",
    "X = df.drop(columns = ['LungCap'])\n",
    "y = df['LungCap']\n",
    "\n",
    "# Instantiate one-hot encoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# columns to be one hot encoded\n",
    "ct = make_column_transformer(\n",
    "\n",
    "    (ohe, ['Smoke', 'Gender', 'Caesarean']),\n",
    "    remainder = 'passthrough')\n",
    "\n",
    "# predictors and target variable\n",
    "X = np.array(ct.fit_transform(X))\n",
    "y = np.array(y)\n",
    "\n",
    "# Checck input and target variable shape\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64dc8c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized feature Mean: 0.0\n",
      "Standardized feature SD : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing subsets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 911)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print('Standardized feature Mean:',  X_train.mean().round())\n",
    "print('Standardized feature SD :',   X_train.std().round())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfdbc7a",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795ffcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=1),\n",
       "                  learning_rate=0.5, n_estimators=10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize AdaBoost Classifier\n",
    "ada = AdaBoostRegressor(\n",
    " DecisionTreeRegressor(max_depth=1), n_estimators=10, learning_rate=0.5)\n",
    "\n",
    "# Fit the model\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4d321",
   "metadata": {},
   "source": [
    "# 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5823c54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 2.836973246539746\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "# Mean squared error\n",
    "print('Mean Squared Error :', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e1263",
   "metadata": {},
   "source": [
    "# 4. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa870d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55289921 0.57933502 0.68654874 0.49889516 0.67031272 0.67832696\n",
      " 0.59131214 0.59631827 0.58271821 0.56166797]\n",
      "R2: 59.983 %\n",
      "Standard Deviation: 5.770 %\n"
     ]
    }
   ],
   "source": [
    "# 10 fold cross validation\n",
    "R2 = cross_val_score(estimator = ada,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             cv = 10,\n",
    "                             scoring = 'r2')\n",
    "\n",
    "# Cross validation accuracy and standard deviation\n",
    "print(R2)\n",
    "print(\"R2: {:.3f} %\".format(R2.mean()*100))\n",
    "print(\"Standard Deviation: {:.3f} %\".format(R2.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054560c",
   "metadata": {},
   "source": [
    "# 5. Hyperparametric Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e60fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 81.95 %\n",
      "Best Parameters: {'learning_rate': 0.5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search CV\n",
    "ada = AdaBoostRegressor()\n",
    "param_grid = [{\n",
    "      'learning_rate': [0.25, 0.5, 1],\n",
    "      'n_estimators': [10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# Configure GridSearchCV\n",
    "grid_search = GridSearchCV(ada, param_grid, cv=5,\n",
    "                                  scoring=\"r2\",\n",
    "                                  n_jobs=-1)\n",
    "\n",
    "# Initiate Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract Tuned Parameters and Predictive Accuracy\n",
    "tuned_params = grid_search.best_params_\n",
    "tuned_score = grid_search.best_score_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Print Results\n",
    "print(\"Best R2: {:.2f} %\".format(grid_search.best_score_*100))\n",
    "print(\"Best Parameters:\", tuned_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "295a3e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 81.72 %\n",
      "Best Parameters: {'n_estimators': 100, 'learning_rate': 2}\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search\n",
    "\n",
    "ada = AdaBoostRegressor()\n",
    "param_grid = [{\n",
    "      'learning_rate': [0.25, 0.5, 1, 2],\n",
    "      'n_estimators': [10, 100, 1000],}]\n",
    "\n",
    "\n",
    "# Configure Randomized Search\n",
    "random_search = RandomizedSearchCV(ada, param_grid,\n",
    "                                        scoring=\"r2\", cv=5, n_iter = 10,\n",
    "                                        n_jobs=-1, random_state=911)\n",
    "#Initiate Search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Extract Tuned Parameters and Predictive Accuracy\n",
    "tuned_params = random_search.best_params_\n",
    "tuned_score = random_search.best_score_\n",
    "best_estimator = random_search.best_estimator_\n",
    "\n",
    "# Print accuracy and best parameters\n",
    "print(\"Best R2: {:.2f} %\".format(random_search.best_score_*100))\n",
    "print(\"Best Parameters:\", tuned_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
